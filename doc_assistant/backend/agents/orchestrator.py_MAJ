from typing import List, Optional
from .chat_agent import Message
from .query_kb_mapper_agent import QueryKBMapper
from .search_agent import SearchAgent, SearchContext
from .no_result_handler_agent import NoResultsHandler, SearchFailureAnalysis
from backend.kb_management.manager import KnowledgeBaseManager
from backend.utils.filter_utils import SearchFilter
import streamlit as st
from typing import Any

class AgentOrchestrator:
    def __init__(
        self,
        kb_manager: KnowledgeBaseManager,
        query_mapper: QueryKBMapper,
        search_agent: SearchAgent,
        llm_service: Any
    ):
        self.kb_manager = kb_manager
        self.query_mapper = query_mapper
        self.search_agent = search_agent
        self.llm = llm_service
        self.no_results_handler = NoResultsHandler(llm_service)
        self.conversation_history: List[Message] = []

    async def process_message(self, message: str, search_filter: Optional[SearchFilter] = None) -> Message:
        """
        Traite un message utilisateur avec gestion am√©lior√©e des √©checs de recherche
        """
        st.info("üì® Traitement du nouveau message")
        self.conversation_history.append(Message(role="user", content=message))

        # Obtenir la liste des bases disponibles
        available_kbs = self.kb_manager.list_knowledge_bases()

        # Si des filtres sont actifs, utiliser la recherche filtr√©e
        if search_filter and search_filter.has_filters():
            kb_ids = search_filter.get_kb_ids()
            st.info(f"üîé Recherche filtr√©e sur {len(kb_ids)} bases")
            search_contexts = await self._filtered_search(message, search_filter)
            
            if not search_contexts:
                st.warning("‚ùå Aucun r√©sultat pour la recherche filtr√©e")
                analysis = await self.no_results_handler.analyze_failed_search(
                    message, 
                    [], 
                    available_kbs
                )
                return self._create_failure_analysis_message(analysis)
                
            if not search_filter or not search_filter.has_filters():
                st.info("ü§ñ Analyse d√©taill√©e des bases pertinentes")
                kb_mappings = await self.query_mapper.map_query_to_kbs(
                    message,
                    min_relevance=0.6,
                    max_kbs=3  # Limiter aux 3 bases les plus pertinentes
                )
                
                if kb_mappings:
                    # Afficher les facteurs de confiance pour transparence
                    self._display_mapping_analysis(kb_mappings)
                    
                    if any(m.relevance_score > 0.8 for m in kb_mappings):
                        st.success("‚úÖ Bases hautement pertinentes identifi√©es")
                    else:
                        st.info("üìä Bases mod√©r√©ment pertinentes trouv√©es")
                else:
                    st.warning("‚ùå Aucune base pertinente trouv√©e")
                    analysis = await self.no_results_handler.analyze_failed_search(
                        message, 
                        self.kb_manager.list_knowledge_bases(),
                        failure_type="no_kb_match"
                    )
                    return self._create_failure_analysis_message(analysis)
                
            st.info(f"üìö {len(kb_mappings)} bases mapp√©es - Lancement recherche")
            search_contexts = await self.search_agent.multi_kb_search(message, kb_mappings)

            # Si aucun r√©sultat, essayer avec les requ√™tes reformul√©es
            if not search_contexts:
                st.warning("‚ùå Aucun r√©sultat trouv√© - Tentative de reformulation")
                analysis = await self.no_results_handler.analyze_failed_search(
                    message,
                    [],
                    available_kbs
                )
                
                if analysis.reformulated_queries:
                    for query in analysis.reformulated_queries:
                        st.info(f"üîÑ Essai avec: {query}")
                        new_contexts = await self.search_agent.multi_kb_search(
                            query,
                            kb_mappings
                        )
                        if new_contexts:
                            st.success("‚úÖ R√©sultats trouv√©s avec la requ√™te reformul√©e")
                            return await self._create_reformulated_response(
                                message, 
                                query, 
                                new_contexts
                            )
                            
                return self._create_failure_analysis_message(analysis)

        st.info(f"‚úÖ {sum(len(ctx.results) for ctx in search_contexts)} segments trouv√©s")
        
        # G√©n√©rer la r√©ponse
        response = await self._generate_response(message, search_contexts)
        response_message = self._create_response_message(response, search_contexts)
        
        self.conversation_history.append(response_message)
        return response_message

    def _display_mapping_analysis(self, mappings: List[KBMappingResult]):
            """Affiche une analyse d√©taill√©e du mapping des bases"""
            with st.expander("üìä Analyse de pertinence des bases", expanded=False):
                for mapping in mappings:
                    st.markdown(f"### Base: {mapping.kb_id}")
                    st.markdown(f"**Score global**: {mapping.relevance_score:.2f}")
                    st.markdown("**Facteurs de confiance**:")
                    
                    # Cr√©er un graphique radar des facteurs
                    factors = mapping.confidence_factors
                    chart_data = {
                        "Facteur": list(factors.keys()),
                        "Score": list(factors.values())
                    }
                    st.bar_chart(chart_data, x="Facteur", y="Score")
                    
                    st.markdown(f"**Raisonnement**: {mapping.reasoning}")
                    st.markdown("---")


    def _create_failure_analysis_message(self, analysis: SearchFailureAnalysis) -> Message:
        """Cr√©e un message d'erreur enrichi avec l'analyse"""
        content = [
            "Je n'ai pas trouv√© de r√©sultats satisfaisants pour votre recherche.",
            "\nCauses possibles :",
            *[f"- {cause}" for cause in analysis.possible_causes],
            "\nSuggestions :",
            *[f"- {action}" for action in analysis.suggested_actions]
        ]
        
        if analysis.reformulated_queries:
            content.extend([
                "\nVous pourriez essayer de reformuler votre question, par exemple :",
                *[f"- {query}" for query in analysis.reformulated_queries]
            ])
        
        return Message(
            role="assistant",
            content="\n".join(content),
            metadata={
                "failure_analysis": {
                    "type": analysis.failure_type,
                    "causes": analysis.possible_causes,
                    "suggestions": analysis.suggested_actions,
                    "reformulations": analysis.reformulated_queries
                }
            }
        )

    async def _create_reformulated_response(
        self,
        original_query: str,
        successful_query: str,
        search_contexts: List[SearchContext]
    ) -> Message:
        """
        Cr√©e une r√©ponse pour une recherche r√©ussie apr√®s reformulation
        """
        response = await self._generate_response(successful_query, search_contexts)
        
        formatted_response = (
            f"J'ai trouv√© des informations pertinentes en reformulant votre question "
            f"\"{original_query}\" en \"{successful_query}\" :\n\n{response}"
        )
        
        return self._create_response_message(
            formatted_response, 
            search_contexts,
            metadata_extra={
                "query_reformulation": {
                    "original": original_query,
                    "successful": successful_query
                }
            }
        )

    async def _filtered_search(
        self, 
        query: str, 
        search_filter: SearchFilter
    ) -> List[SearchContext]:
        """Effectue une recherche dans les bases filtr√©es"""
        st.info("üîç D√©but recherche filtr√©e")
        search_contexts = []
        
        for kb_id in search_filter.get_kb_ids():
            st.info(f"üìñ Recherche dans base: {kb_id}")
            kb = self.kb_manager.load_knowledge_base(kb_id)
            if not kb:
                st.warning(f"‚ùå Base {kb_id} non trouv√©e")
                continue

            metadata_filter = search_filter.to_metadata_filter(kb_id)
            if metadata_filter:
                st.info(f"üìë Filtrage sur {len(search_filter.get_doc_ids(kb_id))} documents")

            results = await self.search_agent.search(
                query=query, 
                kb=kb, 
                filters=metadata_filter
            )

            if results:
                search_contexts.append(SearchContext(
                    kb_id=kb_id,
                    results=results,
                    mapping_score=1.0
                ))
                st.info(f"‚úÖ {len(results)} r√©sultats trouv√©s dans {kb_id}")

        return search_contexts

    async def _generate_response(self, query: str, search_contexts: List[SearchContext]) -> str:
        """G√©n√®re une r√©ponse √† partir des contextes de recherche"""
        context = self._build_context(search_contexts)
        prompt = self._build_response_prompt(query, context)
        messages = [{"role": "user", "content": prompt}]
        return self.llm.make_llm_call(messages)

    def _build_context(self, search_contexts: List[SearchContext]) -> str:
        """Construit le contexte √† partir des r√©sultats de recherche"""
        context_parts = []
        for ctx in search_contexts:
            kb_info = next(
                (kb for kb in self.kb_manager.list_knowledge_bases() 
                 if kb["id"] == ctx.kb_id), 
                {"title": ctx.kb_id}
            )
            context_parts.append(f"\nContexte de la base '{kb_info['title']}':")
            
            for result in ctx.results:
                context_parts.append(
                    f"Document '{result.doc_title}':\n{result.text}\n"
                )
        return "\n".join(context_parts)

    def _build_response_prompt(self, query: str, context: str) -> str:
        """Construit le prompt pour la g√©n√©ration de r√©ponse"""
        return f"""
        Utilise le contexte suivant pour r√©pondre √† la question de mani√®re claire et pr√©cise.
        Cite les sources pertinentes dans ta r√©ponse quand c'est appropri√©.
        
        Contexte:
        {context}

        Question: {query}

        R√©ponse:
        """
    
    def _create_response_message(self, response: str, search_contexts: List[SearchContext], metadata_extra: Optional[dict] = None) -> Message:
        # Enrichir les m√©tadonn√©es avec les facteurs de confiance
        metadata = {
            "sources": [
                {
                    "kb_id": ctx.kb_id,
                    "kb_title": next(
                        (kb["title"] for kb in self.kb_manager.list_knowledge_bases() 
                         if kb["id"] == ctx.kb_id),
                        ctx.kb_id
                    ),
                    "confidence_factors": next(
                        (m.confidence_factors for m in self._current_mappings 
                         if m.kb_id == ctx.kb_id),
                        {}
                    ),
                    "documents": [
                        {
                            "doc_id": result.doc_id,
                            "title": result.doc_title,
                            "relevance": result.relevance_score,
                            "page_numbers": result.page_numbers
                        }
                        for result in ctx.results
                    ]
                }
                for ctx in search_contexts
            ]
        }
        
        if metadata_extra:
            metadata.update(metadata_extra)
        
        return Message(
            role="assistant",
            content=response,
            metadata=metadata
        )